# Toxic comment classifier
ğŸŒˆâœ¨ Toxic Comment Classifier ğŸ§ ğŸ’¬

A Deep Learning + NLP project that detects toxic comments like ğŸ’¢ insults, ğŸš« threats, ğŸ¤¬ obscenities, and ğŸ¥² hate speech.
Built with Python ğŸ, TensorFlow ğŸ”¥, and Gradio ğŸ¨ â€” so you can train models + run a fun interactive web app right from your browser. ğŸš€

ğŸ¯ Features

âœ… Classifies comments into multiple categories:

ğŸ§ª Toxic

ğŸ˜¡ Severe Toxic

ğŸ¤¬ Obscene

ğŸ”ª Threat

ğŸ¤¢ Insult

ğŸ‘¤ Identity Hate

âœ… Built with TensorFlow Deep Learning Models (LSTM / CNN / BiLSTM)
âœ… NLP Pipeline: Tokenization, Stopword Removal, Lemmatization
âœ… Interactive Web App with Gradio ğŸ›ï¸
âœ… Dataset: Kaggle Jigsaw Toxic Comment Classification Challenge ğŸ“Š

ğŸ› ï¸ Tech Stack
Category	Tools Used
ğŸ’» Language	Python ğŸ
ğŸ¤– Deep Learning	TensorFlow / Keras
ğŸ”  NLP	NLTK, SpaCy
ğŸ¨ UI	Gradio
ğŸ“Š Data	Pandas, NumPy
ğŸ“‰ Visualization	Matplotlib, Seaborn


ğŸ“¦ toxic-comment-classifier/
 â”£ ğŸ“œ toxic_classifier.py   # Main script (training + prediction + Gradio app)
 â”£ ğŸ“œ requirements.txt      # Dependencies
 â”£ ğŸ“œ README.md             # Project documentation



ğŸ›¡ï¸ Ethical Considerations âš ï¸

âš–ï¸ This project is for learning & research purposes only.
ğŸ’¡ Models may be biased due to dataset limitations.
ğŸ‘€ Always combine with human moderation in real-world apps.


<img width="1919" height="1022" alt="Screenshot 2025-05-14 115734" src="https://github.com/user-attachments/assets/89b982eb-5a68-4434-bb26-e64ba1b25ba7" />
<img width="1919" height="1021" alt="Screenshot 2025-05-14 115759" src="https://github.com/user-attachments/assets/ab92d8fe-0e73-4c66-8479-1a3102b1523c" />
<img width="1318" height="812" alt="Screenshot 2025-05-14 215137" src="https://github.com/user-attachments/assets/a2a2949a-ee32-433b-aa06-3d4c2bb844f0" />



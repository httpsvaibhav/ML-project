# Toxic comment classifier
A deep learning project that detects toxic comments (such as insults, threats, obscenities, or harassment) using Python, TensorFlow, and Natural Language Processing (NLP).

It also comes with a Gradio-powered web app where you can interactively test comments in real-time 🚀.

🚀 Features

Detects multiple categories of toxicity:

Toxic

Severe Toxic

Obscene

Threat

Insult

Identity Hate

Built with TensorFlow (deep learning model).

Clean NLP pipeline: lowercasing, stopword removal, tokenization, and lemmatization.

Gradio Web App: Try the model in a simple browser UI.

Can be trained on Kaggle’s Jigsaw Toxic Comment dataset.

🛠️ Tech Stack

Language: Python

Deep Learning: TensorFlow / Keras

NLP: NLTK / SpaCy

Web App: Gradio

Data Handling: Pandas, NumPy

Visualization: Matplotlib, Seaborn
